{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0vUVAGgZSpW"
   },
   "source": [
    "#Dataset\n",
    "it consists of three folders test,train and single prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qKxHvwOUCcY"
   },
   "source": [
    "Dataset\n",
    "The problem we will consider here is classifying 4 different building defects . The dataset we will use is collection of 866 images of 4 types of defects \n",
    "\n",
    "The labels in this dataset are the following:\n",
    "<br>\n",
    " **cracks,flakes,roof,spall**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kqoMnDw5VJCT"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljQ3YgE9Kt9M",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MtOtVeDtKt90",
    "outputId": "2aa61060-27aa-4383-c49a-75a7f6327804"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\haris\\\\Desktop\\\\cnn'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OC2Tb4ePKt93"
   },
   "outputs": [],
   "source": [
    "os.chdir('c:\\\\Users\\\\haris\\\\Desktop\\\\cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMcJfVePYlD8"
   },
   "source": [
    "###Data Augmentation\n",
    "To avoid overfitting and create a larger dataset from a smaller one we can use a technique called data augmentation. This is simply performing random transofrmations on our images so that our model can generalize better. These transformations can be things like compressions, rotations, stretches and even color changes. \n",
    "\n",
    "Fortunately, keras can help us do this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqPSzJkCKt97"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-cU8p1KKt9-",
    "outputId": "caea294c-c071-431e-86dd-7b971f674fd0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 662 images belonging to 4 classes.\n",
      "Found 202 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory('Dataset/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                     class_mode = 'categorical')\n",
    "x_test = test_datagen.flow_from_directory('Dataset/test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdDMz7MgKt-B",
    "outputId": "a9645a3c-7c7c-4693-8d6e-ff873f2c1958",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'crack': 0, 'flakes': 1, 'roof': 2, 'spalling': 3}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xsPlrVYZJrb"
   },
   "source": [
    "##CNN Architecture\n",
    "A common architecture for a CNN is a stack of Conv2D and MaxPooling2D layers followed by a few denesly connected layers. To idea is that the stack of convolutional and maxPooling layers extract the features from the image. Then these features are flattened and fed to densly connected layers that determine the class of an image based on the presence of features.\n",
    "\n",
    "We will start by building the **Convolutional Base and then add layers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxcrIiAUVQDq"
   },
   "source": [
    "Layer 1\n",
    "\n",
    "The input shape of our data will be 32, 32, 3 and we will process 32 filters of size 3x3 over our input data. We will also apply the activation function relu to the output of each convolution operation.\n",
    "\n",
    "Layer 2\n",
    "\n",
    "This layer will perform the max pooling operation using 2x2 samples and a stride of 2.\n",
    "\n",
    "Other Layers\n",
    "\n",
    "i didnt keep extra layers for depth of CNN network to make it simple and not too complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXpCn4QGKt9W"
   },
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxJK7xLiKt9c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\haris\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CfCBbAjHKt9h",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\haris\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMnhVbBHKt9k"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lR5eCF0bKt9o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\haris\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=128, activation=\"relu\", kernel_initializer=\"random_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Hidden Layer\n",
    "model.add(Dense(units=128,init=\"random_uniform\",activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0JKrr4_Kt9s"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\haris\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=4, activation=\"softmax\", kernel_initializer=\"random_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Output layer\n",
    "model.add(Dense( units=4,init=\"random_uniform\",activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRedIgn4X_iV",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30752)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3936384   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 3,937,796\n",
      "Trainable params: 3,937,796\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hg4dwBwEY65f"
   },
   "source": [
    "##Training\n",
    "Now we will train and compile the model using the recommended hyper paramaters from tensorflow.\n",
    "\n",
    "*Note: This will take much longer based on number of epochs!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwQFb3Z5Kt9x"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOD1whXBKt-E",
    "outputId": "e6a4c62c-5eae-42e2-a692-9c1f28806d1f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\haris\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/15\n",
      "190/190 [==============================] - 53s 281ms/step - loss: 1.1704 - accuracy: 0.4912 - val_loss: 1.2051 - val_accuracy: 0.3317\n",
      "Epoch 2/15\n",
      "190/190 [==============================] - 54s 287ms/step - loss: 0.8917 - accuracy: 0.6397 - val_loss: 1.1116 - val_accuracy: 0.3911\n",
      "Epoch 3/15\n",
      "190/190 [==============================] - 44s 229ms/step - loss: 0.6916 - accuracy: 0.7322 - val_loss: 2.0580 - val_accuracy: 0.4059\n",
      "Epoch 4/15\n",
      "190/190 [==============================] - 42s 221ms/step - loss: 0.5242 - accuracy: 0.8048 - val_loss: 1.1136 - val_accuracy: 0.4752\n",
      "Epoch 5/15\n",
      "190/190 [==============================] - 44s 231ms/step - loss: 0.4065 - accuracy: 0.8587 - val_loss: 2.0943 - val_accuracy: 0.4307\n",
      "Epoch 6/15\n",
      "190/190 [==============================] - 43s 226ms/step - loss: 0.3162 - accuracy: 0.8863 - val_loss: 2.1421 - val_accuracy: 0.4950\n",
      "Epoch 7/15\n",
      "190/190 [==============================] - 49s 258ms/step - loss: 0.2248 - accuracy: 0.9244 - val_loss: 3.2910 - val_accuracy: 0.5495\n",
      "Epoch 8/15\n",
      "190/190 [==============================] - 48s 254ms/step - loss: 0.2122 - accuracy: 0.9258 - val_loss: 3.1826 - val_accuracy: 0.5248\n",
      "Epoch 9/15\n",
      "190/190 [==============================] - 50s 261ms/step - loss: 0.1565 - accuracy: 0.9477 - val_loss: 2.4090 - val_accuracy: 0.4604\n",
      "Epoch 10/15\n",
      "190/190 [==============================] - 56s 297ms/step - loss: 0.1176 - accuracy: 0.9638 - val_loss: 2.8904 - val_accuracy: 0.5297\n",
      "Epoch 11/15\n",
      "190/190 [==============================] - 50s 263ms/step - loss: 0.0997 - accuracy: 0.9698 - val_loss: 5.4082 - val_accuracy: 0.4455\n",
      "Epoch 12/15\n",
      "190/190 [==============================] - 47s 249ms/step - loss: 0.0759 - accuracy: 0.9774 - val_loss: 3.7852 - val_accuracy: 0.5050\n",
      "Epoch 13/15\n",
      "190/190 [==============================] - 53s 279ms/step - loss: 0.0819 - accuracy: 0.9738 - val_loss: 2.4381 - val_accuracy: 0.5347\n",
      "Epoch 14/15\n",
      "190/190 [==============================] - 53s 279ms/step - loss: 0.0757 - accuracy: 0.9778 - val_loss: 4.7204 - val_accuracy: 0.5099\n",
      "Epoch 15/15\n",
      "190/190 [==============================] - 55s 288ms/step - loss: 0.0670 - accuracy: 0.9802 - val_loss: 4.2260 - val_accuracy: 0.4950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x217eb485488>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,\n",
    "                         steps_per_epoch = 190,\n",
    "                         epochs = 15,\n",
    "                         validation_data = x_test,\n",
    "                         validation_steps = 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jawwGAgKZdGz"
   },
   "source": [
    "#Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kB_RssYiRWLG"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oSRkkXk9Kt-H"
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoHeY7vXZkSl"
   },
   "source": [
    "#Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spNbNPHVRWLM",
    "outputId": "f930f0be-e6bb-455e-a621-c4712402bd37",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model from disk\n",
      "<tensorflow.python.framework.ops.Graph object at 0x00000217EB34CFC8>\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json \n",
    "\n",
    "# opening and store file in a variable\n",
    "\n",
    "json_file = open('model.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "# use Keras model_from_json to make a loaded model\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded Model from disk\")\n",
    "\n",
    "# compile and evaluate loaded model\n",
    "\n",
    "loaded_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#graph = tf.get_default_graph()\n",
    "graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Sw2kx0FZo-N"
   },
   "source": [
    "#Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gWPAbGnkKt-K"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YP7h5q_4RWLR",
    "outputId": "1dc25d9b-0866-4aa9-ee3c-73f53c8496bd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[[0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('Dataset/single_prediction/4.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict_classes(test_image)\n",
    "x_train.class_indices\n",
    "print(result)\n",
    "result_array = model.predict(test_image)\n",
    "print(result_array)\n",
    "\n",
    "if result== 0:\n",
    "  prediction = 'Cracks'\n",
    "elif result == 1:\n",
    "  prediction = 'Flakes'\n",
    "elif result == 2:\n",
    "  prediction = 'roof'\n",
    "else:\n",
    "  prediction = 'Spalling'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6beJvP9Kt-V",
    "outputId": "9531ae14-7462-4402-8032-c6011a7197aa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flakes\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40vgZ-rEYaga"
   },
   "source": [
    "##Evaluating the Model\n",
    "We can determine how well the model performed by looking at it's performance on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXKcwk-XRWLU",
    "outputId": "29f5e881-b40a-4a61-9329-9f87c86c5912",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 9s 135ms/step\n",
      "Final loss: 5.24\n",
      "Final accuracy: 49.50%\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_accuracy = model.evaluate(x_test, steps = 63)\n",
    "print('Final loss: {:.2f}'.format(final_loss))\n",
    "print('Final accuracy: {:.2f}%'.format(final_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDY9gBSSRWLW"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# IMG_INDEX = 7  # change this to look at other images\n",
    "\n",
    "# plt.imshow(x_train[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "# plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzXv312UKt-R"
   },
   "outputs": [],
   "source": [
    "#frame=cv2.imread('C:\\\\Users\\\\haris\\\\Desktop\\\\Section 40 - Convolutional Neural Networks (CNN)\\\\Dataset\\\\test_set\\\\cracks\\\\c5.jpg')\n",
    "#data = detect(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oQTbmuVRWLZ"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "# plt.ylabel('Loss (training and validation)')\n",
    "# plt.xlabel('Training Steps')\n",
    "# plt.ylim([0,50])\n",
    "# plt.plot(hist['loss'])\n",
    "# plt.plot(hist['val_loss'])\n",
    "# plt.figure()\n",
    "# plt.ylabel('Accuracy (training and validation)')\n",
    "# plt.xlabel('Training Steps')\n",
    "# plt.ylim([0,1])\n",
    "# plt.plot(hist['acc'])\n",
    "# plt.plot(hist['val_acc'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Defects in Buildings CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
